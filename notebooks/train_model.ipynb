{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn~=1.0.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: scikit-learn~=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.0.2)\r\nRequirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn~=1.0.0) (2.2.0)\r\nRequirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn~=1.0.0) (1.1.0)\r\nRequirement already satisfied: scipy>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn~=1.0.0) (1.5.2)\r\nRequirement already satisfied: numpy>=1.14.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn~=1.0.0) (1.19.0)\r\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450340049
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450435047
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_id = '93e27594-4e5d-4e68-8b58-7fe0468e93f4'\r\n",
        "resource_group = 'azure-hackathon-2022'\r\n",
        "workspace_name = 'evangelion01'\r\n",
        "\r\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450435344
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sn_kelulusan_all = Dataset.get_by_name(workspace, name='sn_kelulusan_all').to_pandas_dataframe()\r\n",
        "sn_nilai_all = Dataset.get_by_name(workspace, name='sn_nilai_all').to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450438205
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot = sn_nilai_all.pivot_table(index=\"siswa_id\", columns=[\"mapel\"], values=\"nilai\").reset_index()\r\n",
        "df_combined = df_pivot.merge(sn_kelulusan_all, left_on=\"siswa_id\", right_on=\"no_urut\")\r\n",
        "df_cleaned = df_combined.drop(columns=[\"siswa_id\", \"no_urut\"])\r\n",
        "df_cleaned = df_cleaned.fillna(0)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450438312
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   ANTR   BIO   EKO   FIS  GEO   IND   ING  JAP  JER   KIM  ...   PKN   PKR  \\\n0   0.0  84.4  82.2  83.0  0.0  85.4  90.2  0.0  0.0  82.4  ...  89.6  81.2   \n1   0.0  84.8  86.4  83.8  0.0  89.4  87.0  0.0  0.0  82.4  ...  90.8  85.0   \n2   0.0  84.4  85.2  82.2  0.0  86.6  82.2  0.0  0.0  79.0  ...  89.0  84.6   \n3   0.0  85.2  85.2  82.6  0.0  86.8  84.8  0.0  0.0  79.8  ...  87.8  82.8   \n4   0.0  79.2  80.6  80.0  0.0  83.2  85.8  0.0  0.0  77.6  ...  86.2  84.4   \n\n    SBK  SEJ    SI  SIND  SING  SOS   SUN  masuk  \n0  85.0  0.0  81.4   0.0   0.0  0.0  83.8  LOLOS  \n1  85.4  0.0  87.4   0.0   0.0  0.0  86.0  LOLOS  \n2  85.0  0.0  83.0   0.0   0.0  0.0  86.8  TIDAK  \n3  83.0  0.0  83.4   0.0   0.0  0.0  84.6  LOLOS  \n4  82.8  0.0  81.8   0.0   0.0  0.0  82.4  TIDAK  \n\n[5 rows x 24 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ANTR</th>\n      <th>BIO</th>\n      <th>EKO</th>\n      <th>FIS</th>\n      <th>GEO</th>\n      <th>IND</th>\n      <th>ING</th>\n      <th>JAP</th>\n      <th>JER</th>\n      <th>KIM</th>\n      <th>...</th>\n      <th>PKN</th>\n      <th>PKR</th>\n      <th>SBK</th>\n      <th>SEJ</th>\n      <th>SI</th>\n      <th>SIND</th>\n      <th>SING</th>\n      <th>SOS</th>\n      <th>SUN</th>\n      <th>masuk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>84.4</td>\n      <td>82.2</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>85.4</td>\n      <td>90.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>82.4</td>\n      <td>...</td>\n      <td>89.6</td>\n      <td>81.2</td>\n      <td>85.0</td>\n      <td>0.0</td>\n      <td>81.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>83.8</td>\n      <td>LOLOS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>84.8</td>\n      <td>86.4</td>\n      <td>83.8</td>\n      <td>0.0</td>\n      <td>89.4</td>\n      <td>87.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>82.4</td>\n      <td>...</td>\n      <td>90.8</td>\n      <td>85.0</td>\n      <td>85.4</td>\n      <td>0.0</td>\n      <td>87.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.0</td>\n      <td>LOLOS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>84.4</td>\n      <td>85.2</td>\n      <td>82.2</td>\n      <td>0.0</td>\n      <td>86.6</td>\n      <td>82.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>79.0</td>\n      <td>...</td>\n      <td>89.0</td>\n      <td>84.6</td>\n      <td>85.0</td>\n      <td>0.0</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.8</td>\n      <td>TIDAK</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>85.2</td>\n      <td>85.2</td>\n      <td>82.6</td>\n      <td>0.0</td>\n      <td>86.8</td>\n      <td>84.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>79.8</td>\n      <td>...</td>\n      <td>87.8</td>\n      <td>82.8</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>83.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>84.6</td>\n      <td>LOLOS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>79.2</td>\n      <td>80.6</td>\n      <td>80.0</td>\n      <td>0.0</td>\n      <td>83.2</td>\n      <td>85.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>77.6</td>\n      <td>...</td>\n      <td>86.2</td>\n      <td>84.4</td>\n      <td>82.8</td>\n      <td>0.0</td>\n      <td>81.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>82.4</td>\n      <td>TIDAK</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 24 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450438452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = workspace.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450438550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "Index(['ANTR', 'BIO', 'EKO', 'FIS', 'GEO', 'IND', 'ING', 'JAP', 'JER', 'KIM',\n       'MTK', 'MTK_P', 'PAI', 'PJK', 'PKN', 'PKR', 'SBK', 'SEJ', 'SI', 'SIND',\n       'SING', 'SOS', 'SUN', 'masuk'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655451313441
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\r\n",
        "import numpy as np\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450439836
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create experiment and start logging to a new run in the experiment\r\n",
        "experiment_name = \"klasifikasi_snmptn_sklearn\"\r\n",
        "\r\n",
        "# set up MLflow to track the metrics\r\n",
        "mlflow.set_tracking_uri(workspace.get_mlflow_tracking_uri())\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "mlflow.autolog()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022/06/17 07:20:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n2022/06/17 07:20:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n2022/06/17 07:20:41 INFO mlflow.pyspark.ml: No SparkSession detected. Autologging will log pyspark.ml models contained in the default allowlist. To specify a custom allowlist, initialize a SparkSession prior to calling mlflow.pyspark.ml.autolog() and specify the path to your allowlist file via the spark.mlflow.pysparkml.autolog.logModelAllowlistFile conf.\n2022/06/17 07:20:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450440234
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_cleaned.iloc[:, :-1].values\r\n",
        "y = df_cleaned.iloc[:, -1].values\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450440371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GradientBoostingClassifier()\r\n",
        "\r\n",
        "# train the model\r\n",
        "with mlflow.start_run() as run:\r\n",
        "    clf.fit(X_train, y_train)\r\n",
        "    \r\n",
        "    mlflow.sklearn.eval_and_log_metrics(clf, X_test, y_test, prefix=\"val_\")\r\n",
        "\r\n",
        "    model_uri = \"runs:/{}/model\".format(run.info.run_id)\r\n",
        "    model = mlflow.register_model(model_uri, \"klasifikasi_snmptn_sklearn_model\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022/06/17 07:20:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\"\n2022/06/17 07:20:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\"\n2022/06/17 07:20:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.\"\n2022/06/17 07:20:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n  warnings.warn(msg, category=FutureWarning)\n/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n  warnings.warn(msg, category=FutureWarning)\n/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.\n  warnings.warn(msg, category=FutureWarning)\nRegistered model 'klasifikasi_snmptn_sklearn_model' already exists. Creating a new version of this model...\n2022/06/17 07:20:54 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: klasifikasi_snmptn_sklearn_model, version 4\nCreated version '4' of model 'klasifikasi_snmptn_sklearn_model'.\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450453847
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\r\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n       LOLOS       0.51      0.53      0.52        36\n       TIDAK       0.78      0.78      0.78        80\n\n    accuracy                           0.70       116\n   macro avg       0.65      0.65      0.65       116\nweighted avg       0.70      0.70      0.70       116\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450453951
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create environment for the deploy\r\n",
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "from azureml.core.webservice import AciWebservice"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450454120
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a curated environment\r\n",
        "env = Environment.get(\r\n",
        "    workspace=workspace, \r\n",
        "    name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\",\r\n",
        "    version=1\r\n",
        ")\r\n",
        "env.inferencing_stack_version='latest'\r\n",
        "\r\n",
        "# create deployment config i.e. compute resources\r\n",
        "aciconfig = AciWebservice.deploy_configuration(\r\n",
        "    cpu_cores=0.5,\r\n",
        "    memory_gb=0.5,\r\n",
        "    tags={\"data\": \"sn_cleaned\", \"method\": \"sklearn\"},\r\n",
        "    description=\"Model klasifikasi kelulusan SNMPTN menggunakan Gradient Boosting\",\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450454222
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.model import Model"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450454340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the registered model\r\n",
        "model = Model(workspace, \"klasifikasi_snmptn_sklearn_model\")\r\n",
        "\r\n",
        "# create an inference config i.e. the scoring script and environment\r\n",
        "inference_config = InferenceConfig(entry_script=\"serve_snmptn.py\", environment=env)\r\n",
        "\r\n",
        "# deploy the service\r\n",
        "service_name = \"klasifikasi-snmptn-sklearn-\" + str(uuid.uuid4())[:4]\r\n",
        "service = Model.deploy(\r\n",
        "    workspace=workspace,\r\n",
        "    name=service_name,\r\n",
        "    models=[model],\r\n",
        "    inference_config=inference_config,\r\n",
        "    deployment_config=aciconfig,\r\n",
        ")\r\n",
        "\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2022-06-17 07:20:56+00:00 Creating Container Registry if not exists.\n2022-06-17 07:20:56+00:00 Registering the environment.\n2022-06-17 07:20:56+00:00 Use the existing image.\n2022-06-17 07:20:56+00:00 Generating deployment configuration.\n2022-06-17 07:20:58+00:00 Submitting deployment to compute.\n2022-06-17 07:21:02+00:00 Checking the status of deployment klasifikasi-snmptn-sklearn-af92..\n2022-06-17 07:24:42+00:00 Checking the status of inference endpoint klasifikasi-snmptn-sklearn-af92.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655450719852
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}